{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "random_seed = 20\n",
    "import json\n",
    "path = '../../code/para_dict/data_list.json'\n",
    "with open(path,'r',encoding='utf-8') as f:\n",
    "    para = json.loads(f.read())\n",
    "    \n",
    "data_list= para['data_list_FE_AN3']\n",
    "delete_list = para['delete_list_overfit1']\n",
    "\n",
    "def load_data(data_list):\n",
    "    data=[]\n",
    "    for d in data_list:\n",
    "        x = pd.read_csv('../../data/preprocess/{}'.format(d))\n",
    "        x_null = x.isnull().sum()\n",
    "        \n",
    "        print('\\n',d,x.shape)\n",
    "        print(\"Null columns:\\n\",x_null[x_null>0])\n",
    "\n",
    "        if (d=='FE_data1.csv') or (d=='FE_data2.csv'):\n",
    "            x.fillna(value=-1,inplace=True)\n",
    "        \n",
    "        if d[:8]=='FE_data9':\n",
    "            if d!='FE_data9_raw.csv':\n",
    "                x = x.drop(columns=['bacno_shift1','bacno_shiftm1'])\n",
    "        data.append(x)\n",
    "\n",
    "    all_data = pd.concat(data,axis=1)\n",
    "    del data\n",
    "    all_data_numsum = all_data.isnull().sum()\n",
    "    print('ALL data shape:',all_data.shape)\n",
    "    print('ALL data null:')\n",
    "    print(all_data_numsum[all_data_numsum>0])\n",
    "    return all_data\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "all_data = load_data(data_list)\n",
    "category_list=['csmcu','hcefg','stscd','scity','stocn','mcc','acqic',\\\n",
    "                'mchno','etymd','contp','locdt_week']\n",
    "#                 'ovrlt','insfg','ecfg',\\\n",
    "# 'cano_only_consecutive_stscd2','bacno_consecutive_and_only_ecfg','bacno_consecutive_and_only_ecfg',\\\n",
    "# 'cano_lastday_use_twokind','cano_lastlocdt2','bacno_stscd_equal2','bacno_ecfg_equal1']\n",
    "## mode\n",
    "for c in all_data.columns:\n",
    "    print(c)\n",
    "print(all_data.dtypes)\n",
    "\n",
    "for c in category_list:\n",
    "    if all_data[c].dtypes == 'float64':\n",
    "        all_data[c] = all_data[c].astype('int')\n",
    "    all_data[c]=all_data[c].astype('category')\n",
    "\n",
    "for c in all_data.columns[all_data.dtypes==bool]:\n",
    "    all_data[c]=all_data[c].map({True:1,False:0})\n",
    "    print(all_data[c].value_counts())\n",
    "\n",
    "bool_list= ['cano_lastlocdt2_shift1','cano_lastlocdt2_shiftm1','bacno_stscd_equal2_shift1','bacno_stscd_equal2_shiftm1',\\\n",
    "            'bacno_ecfg_equal1_shift1','bacno_ecfg_equal1_shiftm1']\n",
    "for c in bool_list:\n",
    "    if c in all_data.columns:\n",
    "        all_data[c]=all_data[c].map({'True':1,'False':0,'-1':-1})\n",
    "        print(c)\n",
    "        print(all_data[c].value_counts(dropna=False))\n",
    "        print(all_data[c].value_counts().head())\n",
    "    \n",
    "## 切三種不同的訓練集驗證\n",
    "X_train1 = all_data[all_data['locdt']<=60].drop(columns=delete_list)\n",
    "y_train1 = all_data[all_data['locdt']<=60]['fraud_ind']\n",
    "X_test1 = all_data[(all_data['locdt']>60) & (all_data['locdt']<=90)].drop(columns=delete_list)\n",
    "y_test1 = all_data[(all_data['locdt']>60) & (all_data['locdt']<=90)]['fraud_ind']\n",
    "\n",
    "X_train_all = all_data[all_data['locdt']<=90].drop(columns=delete_list)\n",
    "y_train_all = all_data[all_data['locdt']<=90]['fraud_ind'] \n",
    "X_test_all = all_data[all_data['locdt']>90] .drop(columns=delete_list)\n",
    "y_test_all = all_data[all_data['locdt']>90]['fraud_ind'] \n",
    "\n",
    "categorical_features_indices = np.where(X_train1.columns.isin(category_list))[0]\n",
    "print(X_train1.dtypes[categorical_features_indices])\n",
    "\n",
    "param_cat={\n",
    "    'loss_function':'Logloss',\n",
    "    'eval_metric':'F1',\n",
    "    \n",
    "    'iterations':6000,\n",
    "    'scale_pos_weight':1,\n",
    "    'target_border':0.5,\n",
    "    'random_seed':random_seed,\n",
    "    'thread_count':1,\n",
    "    'task_type':\"GPU\",\n",
    "    'devices':'0:1',\n",
    "    'verbose':20,\n",
    "\n",
    "    # 'min_data_in_leaf':1,\n",
    "    # 'has_time':True,\n",
    "\n",
    "    'learning_rate':0.03,\n",
    "    'l2_leaf_reg':1.12,#20\n",
    "    'depth':15,\n",
    "    'max_leaves':38,\n",
    "    'bagging_temperature':0.32,#10\n",
    "    'random_strength':10,\n",
    "    # 'rsm':0.8,\n",
    "\n",
    "    # 'fold_permutation_block':1,\n",
    "    # 'feature_border_type':'MinEntropy',\n",
    "    # 'boosting_type':'Ordered',\n",
    "    # 'leaf_estimation_backtracking':'Armijo',\n",
    "    \n",
    "    'one_hot_max_size':200,\n",
    "    'grow_policy':'Lossguide',\n",
    "    # 'grow_policy':'Depthwise',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**param_cat)\n",
    "model.fit(X_train1, y_train1,\n",
    "cat_features=categorical_features_indices,    \n",
    "eval_set=(X_test1, y_test1),\n",
    "early_stopping_rounds=800,\n",
    "verbose=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred_cat = model.predict_proba(X_test_all)[:,1]\n",
    "# print(y_test_pred_cat.sum(),y_test_pred_cat.shape[0])\n",
    "\n",
    "# th=0.000001\n",
    "# p_id = y_test_pred_cat<=(th)\n",
    "# n_id = y_test_pred_cat>(th)\n",
    "# y_test_pred_cat2 = y_test_pred_cat.copy()\n",
    "# y_test_pred_cat2[p_id]=1\n",
    "# y_test_pred_cat2[n_id]=0\n",
    "# print(y_test_pred_cat2.sum(),y_test_pred_cat2.sum()/y_test_pred_cat2.shape[0])\n",
    "# X_test_all2 = all_data[all_data['locdt']>90]\n",
    "# X_test_all2 = X_test_all2.loc[p_id]\n",
    "# X_test_all2['fraud_ind']=0\n",
    "# X_test_all2.to_csv('../data/preprocess/X_test_select_th0000001_AN7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_cat = model.predict_proba(X_test_all)[:,1]\n",
    "print(y_test_pred_cat.sum(),y_test_pred_cat.shape[0])\n",
    "\n",
    "# th=0.6\n",
    "# p_id = y_test_pred_cat>(th)\n",
    "# n_id = y_test_pred_cat<=(th)\n",
    "# y_test_pred_cat2 = y_test_pred_cat.copy()\n",
    "# y_test_pred_cat2[p_id]=1\n",
    "# y_test_pred_cat2[n_id]=0\n",
    "# print(y_test_pred_cat2.sum(),y_test_pred_cat2.sum()/y_test_pred_cat2.shape[0])\n",
    "# X_test_all2 = all_data[all_data['locdt']>90]\n",
    "# X_test_all2 = X_test_all2.loc[p_id]\n",
    "# X_test_all2['fraud_ind']=1\n",
    "# X_test_all2.to_csv('../data/preprocess/X_test_select_th06_AN7.csv',index=False)\n",
    "\n",
    "# th=0.8\n",
    "# p_id = y_test_pred_cat>(th)\n",
    "# n_id = y_test_pred_cat<=(th)\n",
    "# y_test_pred_cat2 = y_test_pred_cat.copy()\n",
    "# y_test_pred_cat2[p_id]=1\n",
    "# y_test_pred_cat2[n_id]=0\n",
    "# print(y_test_pred_cat2.sum(),y_test_pred_cat2.sum()/y_test_pred_cat2.shape[0])\n",
    "# X_test_all2 = all_data[all_data['locdt']>90]\n",
    "# X_test_all2 = X_test_all2.loc[p_id]\n",
    "# X_test_all2['fraud_ind']=1\n",
    "# X_test_all2.to_csv('../data/preprocess/X_test_select_th08_AN7.csv',index=False)\n",
    "\n",
    "th=0.9\n",
    "p_id = y_test_pred_cat>(th)\n",
    "n_id = y_test_pred_cat<=(th)\n",
    "y_test_pred_cat2 = y_test_pred_cat.copy()\n",
    "y_test_pred_cat2[p_id]=1\n",
    "y_test_pred_cat2[n_id]=0\n",
    "print(y_test_pred_cat2.sum(),y_test_pred_cat2.sum()/y_test_pred_cat2.shape[0])\n",
    "X_test_all2 = all_data[all_data['locdt']>90]\n",
    "X_test_all2 = X_test_all2.loc[p_id]\n",
    "X_test_all2['fraud_ind']=1\n",
    "X_test_all2.to_csv('../../data/preprocess/X_test_select_th09_AN3.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_category(x,target_name):\n",
    "    x_train = x[x['locdt']<=90][target_name].unique()\n",
    "    x_test = x[x['locdt']>90][target_name].unique()\n",
    "    \n",
    "    print(target_name)\n",
    "    print('{} categories in Training data:'.format(x_train.shape[0]))\n",
    "    print('{} categories in Testing data:'.format(x_test.shape[0]))\n",
    "\n",
    "    x_new_test=[]\n",
    "    for b in x_test:\n",
    "        if b not in x_train:\n",
    "            x_new_test.append(b)\n",
    "\n",
    "    print('{} new categories'.format(len(x_new_test)))\n",
    "    return x_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_data2 = all_data.copy()\n",
    "# # 幾乎都太多只出現在test data上的新類別,這樣得轉換可以用來訓練(TODO)\n",
    "\n",
    "# for c in ['mchno','acqic','mcc','stocn','scity','csmcu']:\n",
    "#     new_category = find_new_category(all_data2,c)\n",
    "#     tmp_df = pd.DataFrame(new_category,columns=[c])\n",
    "#     tmp_df['new_{}'.format(c)]=1\n",
    "#     all_data2 = pd.merge(all_data2,tmp_df,on=c,how='left')\n",
    "#     all_data2['new_{}'.format(c)].fillna(value=0,inplace=True)\n",
    "# print(all_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in ['mchno','acqic','mcc','stocn','scity','csmcu']:\n",
    "#     print(all_data2['new_{}'.format(c)].sum())\n",
    "    \n",
    "# all_data2['new_category']=0\n",
    "\n",
    "# for c in ['mchno','acqic','mcc','stocn','scity','csmcu']:\n",
    "#     all_data2['new_category']+=all_data2['new_{}'.format(c)]\n",
    "# print(all_data2['new_category'])\n",
    "# print((all_data2['new_category']>0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_all_data = all_data2[all_data2['locdt']>90]\n",
    "# test_all_data_good = test_all_data['new_category']<1\n",
    "# test_all_data_bad = test_all_data['new_category']>=1\n",
    "# np.save('../data/preprocess/test_data_good_index.npy',test_all_data['new_category']<1)\n",
    "# np.save('../data/preprocess/test_data_bad_index.npy',test_all_data['new_category']>=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
